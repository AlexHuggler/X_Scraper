{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# X_Scraper end-to-end walkthrough\n\nThis notebook demonstrates how to install dependencies, configure the scraper, fetch data, clean it, run sentiment analysis, and generate reports. Edit the configuration values to point at your own API endpoint or adjust thresholds."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "%pip install -q --disable-pip-version-check pandas requests vaderSentiment matplotlib"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Imports and helpers\n\nRun the next cell to load the pipeline components. The package lives in this repository, so you can modify it locally and re-run these cells."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pathlib import Path\n\nimport pandas as pd\n\nfrom x_scraper import ScraperConfig, XScraper"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Configuration\n\nAdjust the values below to control the run:\n\n- `source_url`: API endpoint or JSON feed to scrape.\n- `limit`: Maximum number of records to fetch.\n- `min_chars`: Minimum character length retained after cleaning.\n- `output_dir`: Where CSV outputs will be written.\n- `detail_filename` / `report_filename`: Override output filenames if needed."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "config = ScraperConfig(\n    source_url=\"https://jsonplaceholder.typicode.com/posts\",  # swap in your endpoint\n    limit=25,\n    min_chars=40,\n    output_dir=Path(\"artifacts\"),\n)\nconfig"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Scrape\n\nThe cell below downloads posts from the configured `source_url`. For a different dataset, update the configuration above or inject your own DataFrame if you already have raw content."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "pipeline = XScraper(config)\nraw_posts = pipeline.scrape()\nraw_posts.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Clean the text\n\nThe cleaning step collapses whitespace and trims short entries. Increase `min_chars` if you see noisy, low-value rows, or set it to `0` to keep everything."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "clean_posts = pipeline.clean(raw_posts)\nclean_posts.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Sentiment analysis\n\nVADER sentiment is applied to the cleaned text. The `sentiment_score` is the compound score in `[-1, 1]` and the `sentiment` label is derived from the thresholds used by the analyzer."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "sentiment_posts = pipeline.score_sentiment(clean_posts)\nsentiment_posts[[\"id\", \"sentiment_score\", \"sentiment\"]].head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Reporting\n\nBoth detailed and aggregated reports are saved under `output_dir`:\n\n- `scraped_posts.csv`: Each cleaned post with sentiment columns.\n- `sentiment_report.csv`: Counts of positive/neutral/negative content.\n\nYou can load the outputs into another tool or tweak the DataFrame directly below."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "report_paths = pipeline.generate_reports(sentiment_posts)\nreport_paths"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "summary = sentiment_posts[\"sentiment\"].value_counts().rename_axis(\"sentiment\").reset_index(name=\"count\")\nsummary"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Interpreting the outputs\n\n- Review the `summary` table to see whether your dataset skews positive, neutral, or negative.\n- Inspect the `scraped_posts.csv` file to confirm that cleaning preserved the information you care about.\n- If you need stricter filtering, raise `min_chars` or add extra cleaning rules inside `x_scraper/pipeline.py`.\n- To plug in a different data source, change `source_url` to point at your API, adjust field parsing in `_merge_fields`, and re-run the notebook."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}